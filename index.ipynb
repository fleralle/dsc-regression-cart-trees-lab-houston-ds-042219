{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with CART Trees - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll make use of what we learned in the previous lesson to build a model for the [\"Petrol Consumption Dataset\"](https://www.kaggle.com/harinir/petrol-consumption) from Kaggle. This model will be used to predict gasoline consumption for a bunch of examples, based on drivers' features.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "- Conduct a regression experiment using CART trees\n",
    "- Evaluate the model fit and study the impact of hyper parameters on the final tree\n",
    "- Understand training, prediction, evaluation and visualizations required to run regression experiments using trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset `petrol_consumption.csv` and view its head and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and view head and dimensions\n",
    "df = pd.read_csv('petrol_consumption.csv')\n",
    "df.head()\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the basic statistics for the dataset and inspect the target variable `Petrol_Consumption`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.668333</td>\n",
       "      <td>4241.833333</td>\n",
       "      <td>5565.416667</td>\n",
       "      <td>0.570333</td>\n",
       "      <td>576.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.950770</td>\n",
       "      <td>573.623768</td>\n",
       "      <td>3491.507166</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>111.885816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3063.000000</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>3110.250000</td>\n",
       "      <td>0.529750</td>\n",
       "      <td>509.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>4298.000000</td>\n",
       "      <td>4735.500000</td>\n",
       "      <td>0.564500</td>\n",
       "      <td>568.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.125000</td>\n",
       "      <td>4578.750000</td>\n",
       "      <td>7156.000000</td>\n",
       "      <td>0.595250</td>\n",
       "      <td>632.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5342.000000</td>\n",
       "      <td>17782.000000</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>968.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Petrol_tax  Average_income  Paved_Highways  \\\n",
       "count   48.000000       48.000000       48.000000   \n",
       "mean     7.668333     4241.833333     5565.416667   \n",
       "std      0.950770      573.623768     3491.507166   \n",
       "min      5.000000     3063.000000      431.000000   \n",
       "25%      7.000000     3739.000000     3110.250000   \n",
       "50%      7.500000     4298.000000     4735.500000   \n",
       "75%      8.125000     4578.750000     7156.000000   \n",
       "max     10.000000     5342.000000    17782.000000   \n",
       "\n",
       "       Population_Driver_licence(%)  Petrol_Consumption  \n",
       "count                     48.000000           48.000000  \n",
       "mean                       0.570333          576.770833  \n",
       "std                        0.055470          111.885816  \n",
       "min                        0.451000          344.000000  \n",
       "25%                        0.529750          509.500000  \n",
       "50%                        0.564500          568.500000  \n",
       "75%                        0.595250          632.750000  \n",
       "max                        0.724000          968.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features, labels and train/test datasets with a 80/20 split\n",
    "\n",
    "As with the classification task, we will divide our data into attributes/features and labels and consequently into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create datasets for training and test\n",
    "X = df[['Petrol_tax','Average_income','Paved_Highways','Population_Driver_licence(%)']]\n",
    "y = df.Petrol_Consumption\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of CART regressor and fit the data to the model \n",
    "\n",
    "As mentioned earlier, for a regression task we'll use a different `sklearn` class than we did for the classification task. The class we'll be using here is the `DecisionTreeRegressor` class, as opposed to the `DecisionTreeClassifier` from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a regression tree model with training data \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Using test set, make predictions and calculate the MAE, MSE and RMSE\n",
    " \n",
    "Just as with Decision Trees for classification, there are several commonly used metrics for evaluating the performance of our model. The most common metrics are:\n",
    "\n",
    "* Mean Absolute Error (MAE)\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "\n",
    "If these look familiar, its likely because you have already seen them before--they are common evaluation metrics for any sort of regression model, and as we can see, Regressions performed with Decision Tree models are no exception!\n",
    " \n",
    "Since these are common evaluation metrics, sklearn has functions for each of them that we can use to make our job easier. You'll find these functions inside the `metrics` module. In the cell below, calculate each of the three evaluation metrics listed above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  61.3\n",
      "Mean Squared Error:  6698.3\n",
      "Root Mean Squared Error:  81.84314265715852\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the predictions\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error: ', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a9ed952d03e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Regression function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decision Tree Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4180\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.scatter(X_test, y_test, color = 'red', label='data')\n",
    "plt.plot(X_test, y_pred, color = 'green', label='Regression function')\n",
    "plt.title('Decision Tree Regression')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional \n",
    "\n",
    "- In order to understand and interpret a tree structure, we need some domain knowledge in which the data was generated. That can help us inspect each leaf and investigate/prune the tree based on qualitative analysis. \n",
    "\n",
    "- Look at the hyper parameters used in the regression tree, check their values ranges in official doc and try running some optimization by growing a number of trees in a loop. \n",
    "\n",
    "- Use a dataset that you are familiar with and run tree regression to see if you can interpret the results.\n",
    "\n",
    "- Check for outliers, try normalization and see the impact on the output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we developed a tree regressor architecture to train the regressor and predict values for unseen data. We saw that with a vanilla approach, the results were not so great, and this requires further pre-tuning of the model (what we described as hyper parameter optimization OR pruning in the case of trees. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

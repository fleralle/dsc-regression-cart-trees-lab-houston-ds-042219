{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with CART Trees - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll make use of what we learned in the previous lesson to build a model for the [\"Petrol Consumption Dataset\"](https://www.kaggle.com/harinir/petrol-consumption) from Kaggle. This model will be used to predict gasoline consumption for a bunch of examples, based on drivers' features.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "- Conduct a regression experiment using CART trees\n",
    "- Evaluate the model fit and study the impact of hyper parameters on the final tree\n",
    "- Understand training, prediction, evaluation and visualizations required to run regression experiments using trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset `petrol_consumption.csv` and view its head and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and view head and dimensions\n",
    "df = pd.read_csv('petrol_consumption.csv')\n",
    "df.head()\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the basic statistics for the dataset and inspect the target variable `Petrol_Consumption`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.668333</td>\n",
       "      <td>4241.833333</td>\n",
       "      <td>5565.416667</td>\n",
       "      <td>0.570333</td>\n",
       "      <td>576.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.950770</td>\n",
       "      <td>573.623768</td>\n",
       "      <td>3491.507166</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>111.885816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3063.000000</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>3110.250000</td>\n",
       "      <td>0.529750</td>\n",
       "      <td>509.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>4298.000000</td>\n",
       "      <td>4735.500000</td>\n",
       "      <td>0.564500</td>\n",
       "      <td>568.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.125000</td>\n",
       "      <td>4578.750000</td>\n",
       "      <td>7156.000000</td>\n",
       "      <td>0.595250</td>\n",
       "      <td>632.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5342.000000</td>\n",
       "      <td>17782.000000</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>968.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Petrol_tax  Average_income  Paved_Highways  \\\n",
       "count   48.000000       48.000000       48.000000   \n",
       "mean     7.668333     4241.833333     5565.416667   \n",
       "std      0.950770      573.623768     3491.507166   \n",
       "min      5.000000     3063.000000      431.000000   \n",
       "25%      7.000000     3739.000000     3110.250000   \n",
       "50%      7.500000     4298.000000     4735.500000   \n",
       "75%      8.125000     4578.750000     7156.000000   \n",
       "max     10.000000     5342.000000    17782.000000   \n",
       "\n",
       "       Population_Driver_licence(%)  Petrol_Consumption  \n",
       "count                     48.000000           48.000000  \n",
       "mean                       0.570333          576.770833  \n",
       "std                        0.055470          111.885816  \n",
       "min                        0.451000          344.000000  \n",
       "25%                        0.529750          509.500000  \n",
       "50%                        0.564500          568.500000  \n",
       "75%                        0.595250          632.750000  \n",
       "max                        0.724000          968.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features, labels and train/test datasets with a 80/20 split\n",
    "\n",
    "As with the classification task, we will divide our data into attributes/features and labels and consequently into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create datasets for training and test\n",
    "X = df[['Petrol_tax','Average_income','Paved_Highways','Population_Driver_licence(%)']]\n",
    "y = df.Petrol_Consumption\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of CART regressor and fit the data to the model \n",
    "\n",
    "As mentioned earlier, for a regression task we'll use a different `sklearn` class than we did for the classification task. The class we'll be using here is the `DecisionTreeRegressor` class, as opposed to the `DecisionTreeClassifier` from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a regression tree model with training data \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Using test set, make predictions and calculate the MAE, MSE and RMSE\n",
    " \n",
    "Just as with Decision Trees for classification, there are several commonly used metrics for evaluating the performance of our model. The most common metrics are:\n",
    "\n",
    "* Mean Absolute Error (MAE)\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "\n",
    "If these look familiar, its likely because you have already seen them before--they are common evaluation metrics for any sort of regression model, and as we can see, Regressions performed with Decision Tree models are no exception!\n",
    " \n",
    "Since these are common evaluation metrics, sklearn has functions for each of them that we can use to make our job easier. You'll find these functions inside the `metrics` module. In the cell below, calculate each of the three evaluation metrics listed above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  61.3\n",
      "Mean Squared Error:  6698.3\n",
      "Root Mean Squared Error:  81.84314265715852\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate the predictions\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "print('Mean Absolute Error: ', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error: ', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x, y, and format string must not be None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fdd7001fb47c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Regression function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decision Tree Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# downstream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x, y, and format string must not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x, y, and format string must not be None"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.scatter(y_test, y_test, color = 'red', label='data')\n",
    "plt.plot(y_test, npy_pred.sort(), color = 'green', label='Regression function')\n",
    "plt.title('Decision Tree Regression')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional \n",
    "\n",
    "- In order to understand and interpret a tree structure, we need some domain knowledge in which the data was generated. That can help us inspect each leaf and investigate/prune the tree based on qualitative analysis. \n",
    "\n",
    "- Look at the hyper parameters used in the regression tree, check their values ranges in official doc and try running some optimization by growing a number of trees in a loop. \n",
    "\n",
    "- Use a dataset that you are familiar with and run tree regression to see if you can interpret the results.\n",
    "\n",
    "- Check for outliers, try normalization and see the impact on the output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we developed a tree regressor architecture to train the regressor and predict values for unseen data. We saw that with a vanilla approach, the results were not so great, and this requires further pre-tuning of the model (what we described as hyper parameter optimization OR pruning in the case of trees. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
